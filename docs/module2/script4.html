<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Amazon Simple Storage Service(S3) · AWS Certification Study</title><meta name="viewport" content="width=device-width"/><meta name="generator" content="Docusaurus"/><meta name="description" content="[Heiwad] Amazon Simple Storage Service(Amazon S3)에 대한 소개를 시작하겠습니다. 저는 Heiwad Osman이며 AWS의 기술 강사입니다. Amazon S3를 소개하고, 일반 사용 시나리오를 설명하고, Amazon S3의 빠른 데모를 살펴보겠습니다. 그러면 시작하겠습니다. Amazon S3는 데이터를 저장하고 검색할 수 있는 간단한 API를 제공하는 완전 관리형 스토리지 서비스입니다. 즉, Amazon S3에 저장하는 데이터는 특정 서버와 관련이 없으므로 사용자가 인프라를 직접 관리할 필요가 없습니다. Amazon S3 객체를 원하는 만큼 추가할 수 있습니다. Amazon S3는 수조 개의의 객체를 보유하면서 초당 최대 수백만 개의 요청을 처리합니다. 객체는 이미지, 동영상 또는 서버 로그와 같은 거의 모든 데이터 파일이 될 수 있습니다. Amazon S3는 최대 몇 테라바이트 크기의 객체를 지원하므로, 데이터베이스 스냅샷까지도 객체로 저장할 수도 있습니다. 또한 Amazon S3는 HTTP 또는 HTTPS를 통해 인터넷에서 데이터에 대한 지연 시간이 짧은 액세스를 제공하므로 언제 어디서나 데이터를 검색할 수 있습니다. 또한 가상 사설 클라우드 엔드포인트를 통해 Amazon S3에 비공개적으로 액세스할 수 있습니다. Identity and Access Management 정책, S3 버킷 정책 및 객체별 액세스 제어 목록을 사용하여 데이터에 액세스할 수 있는 사용자를 세밀하게 제어할 수 있습니다. 기본적으로 사용자의 데이터는 공개적으로 공유될 수 없습니다. Y또한 전송 중인 데이터를 암호화하고 객체에서 서버 측 암호화를 사용하도록 지정할 수 있습니다. 이 소개 동영상과 같이 저장할 파일을 가져와 보겠습니다. 먼저 파일을 저장할 위치가 필요합니다. Amazon S3에서 데이터를 보관할 버킷을 생성할 수 있습니다. 이 동영상을 버킷에 객체로 추가하려면 키를 지정해야 합니다. 이 키는 나중에 객체를 검색할 때 사용할 수 있는 문자열입니다. 일반적인 방법은 파일 경로와 유사한 방식으로 문자열을 설정하는 것입니다. 동영상을 해당 키가 포함된 객체로 Amazon S3에 저장하겠습니다. Amazon S3에 버킷을 생성하면 해당 버킷은 특정 AWS 리전에 연결됩니다. 버킷에 데이터를 저장할 때마다 해당 데이터는 선택한 리전의 여러 AWS 시설에 중복 저장됩니다. Amazon S3 서비스는 2개의 AWS 시설에서 동시에 데이터가 손실되는 경우에도 데이터를 안정적으로 저장하도록 설계되었습니다. Amazon S3는 데이터가 증가하더라도 버킷 뒤에서 스토리지를 자동으로 관리합니다. 이를 통해 사용자는 즉시 시작하고 애플리케이션 요구에 따라 데이터 스토리지를 확장할 수 있습니다. 또한 Amazon S3는 많은 양의 요청을 처리할 수 있도록 확장됩니다. 스토리지 또는 처리량을 프로비저닝할 필요가 없으며 사용한 양에 대해서만 비용이 청구됩니다. Amazon S3는 AWS Management Console, AWS CLI 및 SDK를 사용하여 액세스할 수 있습니다. 또한 REST 엔드포인트를 통해 버킷 내 데이터에 직접 액세스할 수 있습니다. HTTP 또는 HTTPS 액세스를 지원합니다. 여기에 버킷 이름, 선택한 리전의 Amazon S3 엔드포인트, 객체를 저장할 때 사용한 키로 구성된 URL의 예가 있습니다. 이 유형의 URL 기반 액세스를 지원하려면 S3 버킷 이름이 전역적으로 고유하고 DNS를 준수해야 합니다. 또한 객체 키는 URL에 안전한 문자를 사용해야 합니다. 사실상 무제한의 데이터를 저장하고 어디서든 해당 데이터에 액세스할 수 있는 이러한 유연성 덕분에 Amazon S3 서비스는 광범위한 시나리오에 적합합니다. Amazon S3의 사용 사례를 몇 가지 살펴보겠습니다. 모든 애플리케이션 데이터의 위치로서, S3 버킷은 EC2 또는 기존 서버의 애플리케이션을 비롯하여 애플리케이션 인스턴스가 액세스할 수 있는 객체를 저장하기 위한 공유 위치를 제공합니다. 이는 사용자 생성 미디어 파일, 서버 로그 또는 애플리케이션에서 공통 위치에 저장해야 하는 다른 파일에 유용할 수 있습니다. 또한 웹에서 직접 콘텐츠를 가져올 수 있기 때문에 애플리케이션이 해당 콘텐츠를 제공할 필요 없이 클라이언트가 Amazon S3에서 직접 데이터를 가져오도록 할 수 있습니다. 정적 웹 호스팅의 경우 S3 버킷은 HTML, CSS, JavaScript 및 기타 파일을 포함하여 웹 사이트의 정적 콘텐츠를 제공할 수 있습니다. Amazon S3는 뛰어난 내구성 덕분에 데이터 백업을 저장할 수 있습니다. 가용성 및 재해 복구 기능을 한층 강화하기 위해 Amazon S3는 한 리전의 S3 버킷에 들어 있는 데이터를 다른 S3 리전으로 자동 복제할 수 있는 교차 리전 복제를 지원하도록 구성할 수도 있습니다. Amazon S3의 확장 가능한 스토리지 및 성능 덕분에 다양한 빅 데이터 도구를 사용하여 분석하려는 데이터를 준비하거나 장기간 보관할 수 있습니다. 예를 들어 Amazon S3의 DataStage는 Amazon Redshift로 로드되어 Amazon EMR에서 처리되거나. Amazon Athena와 같은 도구를 사용하여 쿼리될 수 있습니다. 또한 Snowball과 같은 AWS Import/Export 디바이스를 사용하여 대량의 볼륨을 Amazon S3로 가져오거나 내보낼 수 있습니다. Amazon S3를 사용하여 데이터를 저장하고 액세스하는 것이 매우 간단하므로 AWS 서비스 및 애플리케이션의 다른 부분에 자주 사용되는 것을 쉽게 발견할 수 있습니다. 이제까지 Amazon S3 기능과 일반 사용 사례를 설명했습니다. AWS에서 애플리케이션을 빌드할 때 Amazon S3가 어떻게 도움이 되는지 잘 이해했을 것이라 생각합니다. 이제 Amazon S3 데모를 실행해 보겠습니다. (밝은 선율) 여기는 AWS Management Console의 Amazon S3 섹션인데 각기 다른 버킷 목록이 표시되어 있습니다. 이 섹션에서는 새 버킷을 생성한 다음 데이터를 추가하고, 이 데이터를 검색하겠습니다. 버킷 만들기를 클릭합니다. 여기에 버킷 이름 및 리전 설정 메시지가 표시됩니다. 버킷 이름은 DNS를 준수해야 합니다. 이름을 amazing-bucket-1로 설정하겠습니다. 다음은 리전입니다. 이 경우에는 Amazon EC2 인스턴스에서 실행 중인 애플리케이션이 이 데이터에 액세스해야 하고, 해당 EC2 인스턴스 세트가 오레곤 리전에 있음을 알고 있으므로 리전으로 미국 서부 오레곤으로 설정하겠습니다. 이 시점에서 버킷 생성에 필요한 모든 결정을 내렸습니다. 이 마법사의 나머지 단계는 버킷의 버전 관리 또는 기본 권한 변경과 같은 것들입니다. 권한 변경을 통해 버킷에 대한 액세스를 퍼블릭 인터넷 사용자 또는 특정 AWS 사용자에게 할당할 수 있습니다. 저는 기본값을 원하므로 그냥 생성을 클릭합니다. 이제 버킷이 생성된 것을 확인할 수 있습니다. 이름은 amazing-bucket-1입니다. 버킷을 클릭합니다. 버킷이 비어 있다는 메시지가 표시되고, 새 객체를 업로드할 수 있습니다. 또한 이 버킷에 대한 속성 정보도 볼 수 있습니다. 계속해서 업로드를 클릭합니다. AWS Management Console에서 파일을 끌어다 놓고 파일에 대한 권한을 수정할 수 있습니다. 하지만 저는 AWS CLI를 사용하여 데이터를 업로드하는 것을 선호합니다. 여기에 터미널 창을 열었는데요, 지금 위치는 터미널 창의 Assets라는 폴더입니다. 이곳에 demo.txt 파일이 있습니다. 이 파일을 간단히 살펴보면 TXT 파일이라는 것을 알 수 있습니다, 이제 이 파일을 나중에 제 EC2 인스턴스에서 액세스할 수 있도록 제 S3 버킷에 복사하겠습니다. S3 copy 명령을 사용하여 demo.txt 파일을 amazing-bucket-1에서 hello.txt 키 아래에 있는 객체로 복사하겠습니다. 이제 데이터를 업로드했습니다. 로컬 시스템에 있는 폴더의 내용을 가져올 수 있고, sync 명령을 사용하여 이를 동기화할 수 있습니다. 그러면 AWS CLI가 각 파일을 처리하고 버킷에 있는지 확인한 다음, 버킷에 없는 경우 업로드합니다. 이제 code.zip과 random.csv 파일도 버킷에 업로드했습니다. 계속해서 EC2 인스턴스에 대해 SSH를 수행하고, 인스턴스가 계정의 모든 S3 버킷에 대한 읽기 액세스를 제공하는 IAM 역할로 프로비저닝되었는지 확인할 수 있습니다. 그러면 이 EC2 인스턴스에서 Amazon S3 amazing-bucket-1에 무엇이 있는지 확인해보겠습니다. S3 amazing-bucket-1에 aws s3 ls를 수행하고 이를 반복하여 모든 경로를 확인합니다. 파일이 3개 있음을 알 수 있습니다. 전과 같이 copy 명령을 수행할 수 있지만 지금은 반대로 버킷 이름부터 지정하겠습니다. 버킷에서 hello.txt 파일을 복사했습니다. 계속해서 로컬 EC2 인스턴스 스토리지에서 Is를 수행하면 hello.txt가 표시됩니다. cat을 수행하면 파일을 살펴볼 수 있습니다. TXT 파일이 다운로드 되었다는 것을 알 수 있습니다. sync 명령을 반대로 사용할 수도 있습니다. 그러면 amazing-bucket-1/files의 내용을 EC2 인스턴스의 로컬 폴더로 동기화할 수 있습니다. 이제 폴더가 생성된 것을 확인할 수 있습니다. 이 폴더에는 2개의 파일이 있습니다. code.zip과 random.csv입니다. 이것으로 데이터를 저장하고 데이터를 백업하는 간단한 Amazon S3 시작하기를 살펴본 셈입니다. AWS Management Console로 돌아가 새로 고치겠습니다 이제 S3 버킷에 몇 개의 파일이 있음을 알 수 있습니다. 이들은 관리 콘솔 및 AWS CLI에서 본 것과 동일한 파일입니다. hello.txt를 클릭하면 몇 가지 옵션이 표시됩니다. 이를 통해 객체 기준에 따라 속성 및 권한을 변경할 수 있고, 이 파일의 몇 가지 속성을 볼 수도 있습니다. 이것으로 Amazon S3 서비스 시작하기를 전부 다루었습니다. (밝은 선율) 이 동영상에서는 Amazon S3 개요와 몇 가지 일반적인 사용 사례를 다루었습니다. 또한 데모에서 직접 버킷을 생성하고, 파일을 버킷으로 복사하고, EC2 인스턴스에서 이들 파일을 다운로드했습니다. 시청해 주셔서 감사합니다."/><meta name="docsearch:language" content="en"/><meta property="og:title" content="Amazon Simple Storage Service(S3) · AWS Certification Study"/><meta property="og:type" content="website"/><meta property="og:url" content="https://AUSG.github.io/aws-certification-study/"/><meta property="og:description" content="[Heiwad] Amazon Simple Storage Service(Amazon S3)에 대한 소개를 시작하겠습니다. 저는 Heiwad Osman이며 AWS의 기술 강사입니다. Amazon S3를 소개하고, 일반 사용 시나리오를 설명하고, Amazon S3의 빠른 데모를 살펴보겠습니다. 그러면 시작하겠습니다. Amazon S3는 데이터를 저장하고 검색할 수 있는 간단한 API를 제공하는 완전 관리형 스토리지 서비스입니다. 즉, Amazon S3에 저장하는 데이터는 특정 서버와 관련이 없으므로 사용자가 인프라를 직접 관리할 필요가 없습니다. Amazon S3 객체를 원하는 만큼 추가할 수 있습니다. Amazon S3는 수조 개의의 객체를 보유하면서 초당 최대 수백만 개의 요청을 처리합니다. 객체는 이미지, 동영상 또는 서버 로그와 같은 거의 모든 데이터 파일이 될 수 있습니다. Amazon S3는 최대 몇 테라바이트 크기의 객체를 지원하므로, 데이터베이스 스냅샷까지도 객체로 저장할 수도 있습니다. 또한 Amazon S3는 HTTP 또는 HTTPS를 통해 인터넷에서 데이터에 대한 지연 시간이 짧은 액세스를 제공하므로 언제 어디서나 데이터를 검색할 수 있습니다. 또한 가상 사설 클라우드 엔드포인트를 통해 Amazon S3에 비공개적으로 액세스할 수 있습니다. Identity and Access Management 정책, S3 버킷 정책 및 객체별 액세스 제어 목록을 사용하여 데이터에 액세스할 수 있는 사용자를 세밀하게 제어할 수 있습니다. 기본적으로 사용자의 데이터는 공개적으로 공유될 수 없습니다. Y또한 전송 중인 데이터를 암호화하고 객체에서 서버 측 암호화를 사용하도록 지정할 수 있습니다. 이 소개 동영상과 같이 저장할 파일을 가져와 보겠습니다. 먼저 파일을 저장할 위치가 필요합니다. Amazon S3에서 데이터를 보관할 버킷을 생성할 수 있습니다. 이 동영상을 버킷에 객체로 추가하려면 키를 지정해야 합니다. 이 키는 나중에 객체를 검색할 때 사용할 수 있는 문자열입니다. 일반적인 방법은 파일 경로와 유사한 방식으로 문자열을 설정하는 것입니다. 동영상을 해당 키가 포함된 객체로 Amazon S3에 저장하겠습니다. Amazon S3에 버킷을 생성하면 해당 버킷은 특정 AWS 리전에 연결됩니다. 버킷에 데이터를 저장할 때마다 해당 데이터는 선택한 리전의 여러 AWS 시설에 중복 저장됩니다. Amazon S3 서비스는 2개의 AWS 시설에서 동시에 데이터가 손실되는 경우에도 데이터를 안정적으로 저장하도록 설계되었습니다. Amazon S3는 데이터가 증가하더라도 버킷 뒤에서 스토리지를 자동으로 관리합니다. 이를 통해 사용자는 즉시 시작하고 애플리케이션 요구에 따라 데이터 스토리지를 확장할 수 있습니다. 또한 Amazon S3는 많은 양의 요청을 처리할 수 있도록 확장됩니다. 스토리지 또는 처리량을 프로비저닝할 필요가 없으며 사용한 양에 대해서만 비용이 청구됩니다. Amazon S3는 AWS Management Console, AWS CLI 및 SDK를 사용하여 액세스할 수 있습니다. 또한 REST 엔드포인트를 통해 버킷 내 데이터에 직접 액세스할 수 있습니다. HTTP 또는 HTTPS 액세스를 지원합니다. 여기에 버킷 이름, 선택한 리전의 Amazon S3 엔드포인트, 객체를 저장할 때 사용한 키로 구성된 URL의 예가 있습니다. 이 유형의 URL 기반 액세스를 지원하려면 S3 버킷 이름이 전역적으로 고유하고 DNS를 준수해야 합니다. 또한 객체 키는 URL에 안전한 문자를 사용해야 합니다. 사실상 무제한의 데이터를 저장하고 어디서든 해당 데이터에 액세스할 수 있는 이러한 유연성 덕분에 Amazon S3 서비스는 광범위한 시나리오에 적합합니다. Amazon S3의 사용 사례를 몇 가지 살펴보겠습니다. 모든 애플리케이션 데이터의 위치로서, S3 버킷은 EC2 또는 기존 서버의 애플리케이션을 비롯하여 애플리케이션 인스턴스가 액세스할 수 있는 객체를 저장하기 위한 공유 위치를 제공합니다. 이는 사용자 생성 미디어 파일, 서버 로그 또는 애플리케이션에서 공통 위치에 저장해야 하는 다른 파일에 유용할 수 있습니다. 또한 웹에서 직접 콘텐츠를 가져올 수 있기 때문에 애플리케이션이 해당 콘텐츠를 제공할 필요 없이 클라이언트가 Amazon S3에서 직접 데이터를 가져오도록 할 수 있습니다. 정적 웹 호스팅의 경우 S3 버킷은 HTML, CSS, JavaScript 및 기타 파일을 포함하여 웹 사이트의 정적 콘텐츠를 제공할 수 있습니다. Amazon S3는 뛰어난 내구성 덕분에 데이터 백업을 저장할 수 있습니다. 가용성 및 재해 복구 기능을 한층 강화하기 위해 Amazon S3는 한 리전의 S3 버킷에 들어 있는 데이터를 다른 S3 리전으로 자동 복제할 수 있는 교차 리전 복제를 지원하도록 구성할 수도 있습니다. Amazon S3의 확장 가능한 스토리지 및 성능 덕분에 다양한 빅 데이터 도구를 사용하여 분석하려는 데이터를 준비하거나 장기간 보관할 수 있습니다. 예를 들어 Amazon S3의 DataStage는 Amazon Redshift로 로드되어 Amazon EMR에서 처리되거나. Amazon Athena와 같은 도구를 사용하여 쿼리될 수 있습니다. 또한 Snowball과 같은 AWS Import/Export 디바이스를 사용하여 대량의 볼륨을 Amazon S3로 가져오거나 내보낼 수 있습니다. Amazon S3를 사용하여 데이터를 저장하고 액세스하는 것이 매우 간단하므로 AWS 서비스 및 애플리케이션의 다른 부분에 자주 사용되는 것을 쉽게 발견할 수 있습니다. 이제까지 Amazon S3 기능과 일반 사용 사례를 설명했습니다. AWS에서 애플리케이션을 빌드할 때 Amazon S3가 어떻게 도움이 되는지 잘 이해했을 것이라 생각합니다. 이제 Amazon S3 데모를 실행해 보겠습니다. (밝은 선율) 여기는 AWS Management Console의 Amazon S3 섹션인데 각기 다른 버킷 목록이 표시되어 있습니다. 이 섹션에서는 새 버킷을 생성한 다음 데이터를 추가하고, 이 데이터를 검색하겠습니다. 버킷 만들기를 클릭합니다. 여기에 버킷 이름 및 리전 설정 메시지가 표시됩니다. 버킷 이름은 DNS를 준수해야 합니다. 이름을 amazing-bucket-1로 설정하겠습니다. 다음은 리전입니다. 이 경우에는 Amazon EC2 인스턴스에서 실행 중인 애플리케이션이 이 데이터에 액세스해야 하고, 해당 EC2 인스턴스 세트가 오레곤 리전에 있음을 알고 있으므로 리전으로 미국 서부 오레곤으로 설정하겠습니다. 이 시점에서 버킷 생성에 필요한 모든 결정을 내렸습니다. 이 마법사의 나머지 단계는 버킷의 버전 관리 또는 기본 권한 변경과 같은 것들입니다. 권한 변경을 통해 버킷에 대한 액세스를 퍼블릭 인터넷 사용자 또는 특정 AWS 사용자에게 할당할 수 있습니다. 저는 기본값을 원하므로 그냥 생성을 클릭합니다. 이제 버킷이 생성된 것을 확인할 수 있습니다. 이름은 amazing-bucket-1입니다. 버킷을 클릭합니다. 버킷이 비어 있다는 메시지가 표시되고, 새 객체를 업로드할 수 있습니다. 또한 이 버킷에 대한 속성 정보도 볼 수 있습니다. 계속해서 업로드를 클릭합니다. AWS Management Console에서 파일을 끌어다 놓고 파일에 대한 권한을 수정할 수 있습니다. 하지만 저는 AWS CLI를 사용하여 데이터를 업로드하는 것을 선호합니다. 여기에 터미널 창을 열었는데요, 지금 위치는 터미널 창의 Assets라는 폴더입니다. 이곳에 demo.txt 파일이 있습니다. 이 파일을 간단히 살펴보면 TXT 파일이라는 것을 알 수 있습니다, 이제 이 파일을 나중에 제 EC2 인스턴스에서 액세스할 수 있도록 제 S3 버킷에 복사하겠습니다. S3 copy 명령을 사용하여 demo.txt 파일을 amazing-bucket-1에서 hello.txt 키 아래에 있는 객체로 복사하겠습니다. 이제 데이터를 업로드했습니다. 로컬 시스템에 있는 폴더의 내용을 가져올 수 있고, sync 명령을 사용하여 이를 동기화할 수 있습니다. 그러면 AWS CLI가 각 파일을 처리하고 버킷에 있는지 확인한 다음, 버킷에 없는 경우 업로드합니다. 이제 code.zip과 random.csv 파일도 버킷에 업로드했습니다. 계속해서 EC2 인스턴스에 대해 SSH를 수행하고, 인스턴스가 계정의 모든 S3 버킷에 대한 읽기 액세스를 제공하는 IAM 역할로 프로비저닝되었는지 확인할 수 있습니다. 그러면 이 EC2 인스턴스에서 Amazon S3 amazing-bucket-1에 무엇이 있는지 확인해보겠습니다. S3 amazing-bucket-1에 aws s3 ls를 수행하고 이를 반복하여 모든 경로를 확인합니다. 파일이 3개 있음을 알 수 있습니다. 전과 같이 copy 명령을 수행할 수 있지만 지금은 반대로 버킷 이름부터 지정하겠습니다. 버킷에서 hello.txt 파일을 복사했습니다. 계속해서 로컬 EC2 인스턴스 스토리지에서 Is를 수행하면 hello.txt가 표시됩니다. cat을 수행하면 파일을 살펴볼 수 있습니다. TXT 파일이 다운로드 되었다는 것을 알 수 있습니다. sync 명령을 반대로 사용할 수도 있습니다. 그러면 amazing-bucket-1/files의 내용을 EC2 인스턴스의 로컬 폴더로 동기화할 수 있습니다. 이제 폴더가 생성된 것을 확인할 수 있습니다. 이 폴더에는 2개의 파일이 있습니다. code.zip과 random.csv입니다. 이것으로 데이터를 저장하고 데이터를 백업하는 간단한 Amazon S3 시작하기를 살펴본 셈입니다. AWS Management Console로 돌아가 새로 고치겠습니다 이제 S3 버킷에 몇 개의 파일이 있음을 알 수 있습니다. 이들은 관리 콘솔 및 AWS CLI에서 본 것과 동일한 파일입니다. hello.txt를 클릭하면 몇 가지 옵션이 표시됩니다. 이를 통해 객체 기준에 따라 속성 및 권한을 변경할 수 있고, 이 파일의 몇 가지 속성을 볼 수도 있습니다. 이것으로 Amazon S3 서비스 시작하기를 전부 다루었습니다. (밝은 선율) 이 동영상에서는 Amazon S3 개요와 몇 가지 일반적인 사용 사례를 다루었습니다. 또한 데모에서 직접 버킷을 생성하고, 파일을 버킷으로 복사하고, EC2 인스턴스에서 이들 파일을 다운로드했습니다. 시청해 주셔서 감사합니다."/><meta property="og:image" content="https://AUSG.github.io/aws-certification-study/img/undraw_online.svg"/><meta name="twitter:card" content="summary"/><meta name="twitter:image" content="https://AUSG.github.io/aws-certification-study/img/undraw_tweetstorm.svg"/><link rel="shortcut icon" href="/aws-certification-study/img/ausg logo.ico"/><link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css"/><script type="text/javascript" src="https://buttons.github.io/buttons.js"></script><script src="/aws-certification-study/js/scrollSpy.js"></script><link rel="stylesheet" href="/aws-certification-study/css/main.css"/><script src="/aws-certification-study/js/codetabs.js"></script></head><body class="sideNavVisible separateOnPageNav"><div class="fixedHeaderContainer"><div class="headerWrapper wrapper"><header><a href="/aws-certification-study/"><img class="logo" src="/aws-certification-study/img/ausg logo.png" alt="AWS Certification Study"/><h2 class="headerTitleWithLogo">AWS Certification Study</h2></a><div class="navigationWrapper navigationSlider"><nav class="slidingNav"><ul class="nav-site nav-site-internal"><li class="siteNavGroupActive"><a href="/aws-certification-study/docs/doc1" target="_self">Docs</a></li><li class=""><a href="/aws-certification-study/users" target="_self">Authors</a></li></ul></nav></div></header></div></div><div class="navPusher"><div class="docMainWrapper wrapper"><div class="docsNavContainer" id="docsNav"><nav class="toc"><div class="toggleNav"><section class="navWrapper wrapper"><div class="navBreadcrumb wrapper"><div class="navToggle" id="navToggler"><div class="hamburger-menu"><div class="line1"></div><div class="line2"></div><div class="line3"></div></div></div><h2><i>›</i><span>Module2: AWS Core Services</span></h2><div class="tocToggler" id="tocToggler"><i class="icon-toc"></i></div></div><div class="navGroups"><div class="navGroup"><h3 class="navGroupCategoryTitle">AWS Cloud Practitioner</h3><ul class=""><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/doc1">소개</a></li><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Module1: Introduction to the AWS Cloud</h4><ul><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module1/script1">모듈 소개</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module1/script2">AWS 클라우드 소개</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module1/script3">AWS 인터페이스 소개</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module1/script_en">Introduction to AWS Cloud</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module1/summary">요약</a></li></ul></div><div class="navGroup subNavGroup"><h4 class="navGroupSubcategoryTitle">Module2: AWS Core Services</h4><ul><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module2/script1">모듈 소개</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module2/script2">Amazon Elastic Cloud Compute(EC2)</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module2/script3">Amazon Elastic Block Store(Amazon EBS)</a></li><li class="navListItem navListItemActive"><a class="navItem" href="/aws-certification-study/docs/module2/script4">Amazon Simple Storage Service(S3)</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module2/script5">AWS 글로벌 인프라</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module2/script6">Virtual Private Cloud(VPC)</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module2/script7">AWS 보안 그룹</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module2/script_en">AWS Core Services</a></li><li class="navListItem"><a class="navItem" href="/aws-certification-study/docs/module2/summary">요약</a></li></ul></div></ul></div></div></section></div><script>
            var coll = document.getElementsByClassName('collapsible');
            var checkActiveCategory = true;
            for (var i = 0; i < coll.length; i++) {
              var links = coll[i].nextElementSibling.getElementsByTagName('*');
              if (checkActiveCategory){
                for (var j = 0; j < links.length; j++) {
                  if (links[j].classList.contains('navListItemActive')){
                    coll[i].nextElementSibling.classList.toggle('hide');
                    coll[i].childNodes[1].classList.toggle('rotate');
                    checkActiveCategory = false;
                    break;
                  }
                }
              }

              coll[i].addEventListener('click', function() {
                var arrow = this.childNodes[1];
                arrow.classList.toggle('rotate');
                var content = this.nextElementSibling;
                content.classList.toggle('hide');
              });
            }

            document.addEventListener('DOMContentLoaded', function() {
              createToggler('#navToggler', '#docsNav', 'docsSliderActive');
              createToggler('#tocToggler', 'body', 'tocActive');

              var headings = document.querySelector('.toc-headings');
              headings && headings.addEventListener('click', function(event) {
                var el = event.target;
                while(el !== headings){
                  if (el.tagName === 'A') {
                    document.body.classList.remove('tocActive');
                    break;
                  } else{
                    el = el.parentNode;
                  }
                }
              }, false);

              function createToggler(togglerSelector, targetSelector, className) {
                var toggler = document.querySelector(togglerSelector);
                var target = document.querySelector(targetSelector);

                if (!toggler) {
                  return;
                }

                toggler.onclick = function(event) {
                  event.preventDefault();

                  target.classList.toggle(className);
                };
              }
            });
        </script></nav></div><div class="container mainContainer"><div class="wrapper"><div class="post"><header class="postHeader"><h1 class="postHeaderTitle">Amazon Simple Storage Service(S3)</h1></header><article><div><span><p>[Heiwad] Amazon Simple Storage Service(Amazon S3)에 대한 소개를 시작하겠습니다. 저는 Heiwad Osman이며 AWS의 기술 강사입니다. Amazon S3를 소개하고, 일반 사용 시나리오를 설명하고, Amazon S3의 빠른 데모를 살펴보겠습니다. 그러면 시작하겠습니다. Amazon S3는 데이터를 저장하고 검색할 수 있는 간단한 API를 제공하는 완전 관리형 스토리지 서비스입니다. 즉, Amazon S3에 저장하는 데이터는 특정 서버와 관련이 없으므로 사용자가 인프라를 직접 관리할 필요가 없습니다. Amazon S3 객체를 원하는 만큼 추가할 수 있습니다. Amazon S3는 수조 개의의 객체를 보유하면서 초당 최대 수백만 개의 요청을 처리합니다. 객체는 이미지, 동영상 또는 서버 로그와 같은 거의 모든 데이터 파일이 될 수 있습니다. Amazon S3는 최대 몇 테라바이트 크기의 객체를 지원하므로, 데이터베이스 스냅샷까지도 객체로 저장할 수도 있습니다. 또한 Amazon S3는 HTTP 또는 HTTPS를 통해 인터넷에서 데이터에 대한 지연 시간이 짧은 액세스를 제공하므로 언제 어디서나 데이터를 검색할 수 있습니다. 또한 가상 사설 클라우드 엔드포인트를 통해 Amazon S3에 비공개적으로 액세스할 수 있습니다. Identity and Access Management 정책, S3 버킷 정책 및 객체별 액세스 제어 목록을 사용하여 데이터에 액세스할 수 있는 사용자를 세밀하게 제어할 수 있습니다. 기본적으로 사용자의 데이터는 공개적으로 공유될 수 없습니다. Y또한 전송 중인 데이터를 암호화하고 객체에서 서버 측 암호화를 사용하도록 지정할 수 있습니다. 이 소개 동영상과 같이 저장할 파일을 가져와 보겠습니다. 먼저 파일을 저장할 위치가 필요합니다. Amazon S3에서 데이터를 보관할 버킷을 생성할 수 있습니다. 이 동영상을 버킷에 객체로 추가하려면 키를 지정해야 합니다. 이 키는 나중에 객체를 검색할 때 사용할 수 있는 문자열입니다. 일반적인 방법은 파일 경로와 유사한 방식으로 문자열을 설정하는 것입니다. 동영상을 해당 키가 포함된 객체로 Amazon S3에 저장하겠습니다. Amazon S3에 버킷을 생성하면 해당 버킷은 특정 AWS 리전에 연결됩니다. 버킷에 데이터를 저장할 때마다 해당 데이터는 선택한 리전의 여러 AWS 시설에 중복 저장됩니다. Amazon S3 서비스는 2개의 AWS 시설에서 동시에 데이터가 손실되는 경우에도 데이터를 안정적으로 저장하도록 설계되었습니다. Amazon S3는 데이터가 증가하더라도 버킷 뒤에서 스토리지를 자동으로 관리합니다. 이를 통해 사용자는 즉시 시작하고 애플리케이션 요구에 따라 데이터 스토리지를 확장할 수 있습니다. 또한 Amazon S3는 많은 양의 요청을 처리할 수 있도록 확장됩니다. 스토리지 또는 처리량을 프로비저닝할 필요가 없으며 사용한 양에 대해서만 비용이 청구됩니다. Amazon S3는 AWS Management Console, AWS CLI 및 SDK를 사용하여 액세스할 수 있습니다. 또한 REST 엔드포인트를 통해 버킷 내 데이터에 직접 액세스할 수 있습니다. HTTP 또는 HTTPS 액세스를 지원합니다. 여기에 버킷 이름, 선택한 리전의 Amazon S3 엔드포인트, 객체를 저장할 때 사용한 키로 구성된 URL의 예가 있습니다. 이 유형의 URL 기반 액세스를 지원하려면 S3 버킷 이름이 전역적으로 고유하고 DNS를 준수해야 합니다. 또한 객체 키는 URL에 안전한 문자를 사용해야 합니다. 사실상 무제한의 데이터를 저장하고 어디서든 해당 데이터에 액세스할 수 있는 이러한 유연성 덕분에 Amazon S3 서비스는 광범위한 시나리오에 적합합니다. Amazon S3의 사용 사례를 몇 가지 살펴보겠습니다. 모든 애플리케이션 데이터의 위치로서, S3 버킷은 EC2 또는 기존 서버의 애플리케이션을 비롯하여 애플리케이션 인스턴스가 액세스할 수 있는 객체를 저장하기 위한 공유 위치를 제공합니다. 이는 사용자 생성 미디어 파일, 서버 로그 또는 애플리케이션에서 공통 위치에 저장해야 하는 다른 파일에 유용할 수 있습니다. 또한 웹에서 직접 콘텐츠를 가져올 수 있기 때문에 애플리케이션이 해당 콘텐츠를 제공할 필요 없이 클라이언트가 Amazon S3에서 직접 데이터를 가져오도록 할 수 있습니다. 정적 웹 호스팅의 경우 S3 버킷은 HTML, CSS, JavaScript 및 기타 파일을 포함하여 웹 사이트의 정적 콘텐츠를 제공할 수 있습니다. Amazon S3는 뛰어난 내구성 덕분에 데이터 백업을 저장할 수 있습니다. 가용성 및 재해 복구 기능을 한층 강화하기 위해 Amazon S3는 한 리전의 S3 버킷에 들어 있는 데이터를 다른 S3 리전으로 자동 복제할 수 있는 교차 리전 복제를 지원하도록 구성할 수도 있습니다. Amazon S3의 확장 가능한 스토리지 및 성능 덕분에 다양한 빅 데이터 도구를 사용하여 분석하려는 데이터를 준비하거나 장기간 보관할 수 있습니다. 예를 들어 Amazon S3의 DataStage는 Amazon Redshift로 로드되어 Amazon EMR에서 처리되거나. Amazon Athena와 같은 도구를 사용하여 쿼리될 수 있습니다. 또한 Snowball과 같은 AWS Import/Export 디바이스를 사용하여 대량의 볼륨을 Amazon S3로 가져오거나 내보낼 수 있습니다. Amazon S3를 사용하여 데이터를 저장하고 액세스하는 것이 매우 간단하므로 AWS 서비스 및 애플리케이션의 다른 부분에 자주 사용되는 것을 쉽게 발견할 수 있습니다. 이제까지 Amazon S3 기능과 일반 사용 사례를 설명했습니다. AWS에서 애플리케이션을 빌드할 때 Amazon S3가 어떻게 도움이 되는지 잘 이해했을 것이라 생각합니다. 이제 Amazon S3 데모를 실행해 보겠습니다. (밝은 선율) 여기는 AWS Management Console의 Amazon S3 섹션인데 각기 다른 버킷 목록이 표시되어 있습니다. 이 섹션에서는 새 버킷을 생성한 다음 데이터를 추가하고, 이 데이터를 검색하겠습니다. 버킷 만들기를 클릭합니다. 여기에 버킷 이름 및 리전 설정 메시지가 표시됩니다. 버킷 이름은 DNS를 준수해야 합니다. 이름을 amazing-bucket-1로 설정하겠습니다. 다음은 리전입니다. 이 경우에는 Amazon EC2 인스턴스에서 실행 중인 애플리케이션이 이 데이터에 액세스해야 하고, 해당 EC2 인스턴스 세트가 오레곤 리전에 있음을 알고 있으므로 리전으로 미국 서부 오레곤으로 설정하겠습니다. 이 시점에서 버킷 생성에 필요한 모든 결정을 내렸습니다. 이 마법사의 나머지 단계는 버킷의 버전 관리 또는 기본 권한 변경과 같은 것들입니다. 권한 변경을 통해 버킷에 대한 액세스를 퍼블릭 인터넷 사용자 또는 특정 AWS 사용자에게 할당할 수 있습니다. 저는 기본값을 원하므로 그냥 생성을 클릭합니다. 이제 버킷이 생성된 것을 확인할 수 있습니다. 이름은 amazing-bucket-1입니다. 버킷을 클릭합니다. 버킷이 비어 있다는 메시지가 표시되고, 새 객체를 업로드할 수 있습니다. 또한 이 버킷에 대한 속성 정보도 볼 수 있습니다. 계속해서 업로드를 클릭합니다. AWS Management Console에서 파일을 끌어다 놓고 파일에 대한 권한을 수정할 수 있습니다. 하지만 저는 AWS CLI를 사용하여 데이터를 업로드하는 것을 선호합니다. 여기에 터미널 창을 열었는데요, 지금 위치는 터미널 창의 Assets라는 폴더입니다. 이곳에 demo.txt 파일이 있습니다. 이 파일을 간단히 살펴보면 TXT 파일이라는 것을 알 수 있습니다, 이제 이 파일을 나중에 제 EC2 인스턴스에서 액세스할 수 있도록 제 S3 버킷에 복사하겠습니다. S3 copy 명령을 사용하여 demo.txt 파일을 amazing-bucket-1에서 hello.txt 키 아래에 있는 객체로 복사하겠습니다. 이제 데이터를 업로드했습니다. 로컬 시스템에 있는 폴더의 내용을 가져올 수 있고, sync 명령을 사용하여 이를 동기화할 수 있습니다. 그러면 AWS CLI가 각 파일을 처리하고 버킷에 있는지 확인한 다음, 버킷에 없는 경우 업로드합니다. 이제 code.zip과 random.csv 파일도 버킷에 업로드했습니다. 계속해서 EC2 인스턴스에 대해 SSH를 수행하고, 인스턴스가 계정의 모든 S3 버킷에 대한 읽기 액세스를 제공하는 IAM 역할로 프로비저닝되었는지 확인할 수 있습니다. 그러면 이 EC2 인스턴스에서 Amazon S3 amazing-bucket-1에 무엇이 있는지 확인해보겠습니다. S3 amazing-bucket-1에 aws s3 ls를 수행하고 이를 반복하여 모든 경로를 확인합니다. 파일이 3개 있음을 알 수 있습니다. 전과 같이 copy 명령을 수행할 수 있지만 지금은 반대로 버킷 이름부터 지정하겠습니다. 버킷에서 hello.txt 파일을 복사했습니다. 계속해서 로컬 EC2 인스턴스 스토리지에서 Is를 수행하면 hello.txt가 표시됩니다. cat을 수행하면 파일을 살펴볼 수 있습니다. TXT 파일이 다운로드 되었다는 것을 알 수 있습니다. sync 명령을 반대로 사용할 수도 있습니다. 그러면 amazing-bucket-1/files의 내용을 EC2 인스턴스의 로컬 폴더로 동기화할 수 있습니다. 이제 폴더가 생성된 것을 확인할 수 있습니다. 이 폴더에는 2개의 파일이 있습니다. code.zip과 random.csv입니다. 이것으로 데이터를 저장하고 데이터를 백업하는 간단한 Amazon S3 시작하기를 살펴본 셈입니다. AWS Management Console로 돌아가 새로 고치겠습니다 이제 S3 버킷에 몇 개의 파일이 있음을 알 수 있습니다. 이들은 관리 콘솔 및 AWS CLI에서 본 것과 동일한 파일입니다. hello.txt를 클릭하면 몇 가지 옵션이 표시됩니다. 이를 통해 객체 기준에 따라 속성 및 권한을 변경할 수 있고, 이 파일의 몇 가지 속성을 볼 수도 있습니다. 이것으로 Amazon S3 서비스 시작하기를 전부 다루었습니다. (밝은 선율) 이 동영상에서는 Amazon S3 개요와 몇 가지 일반적인 사용 사례를 다루었습니다. 또한 데모에서 직접 버킷을 생성하고, 파일을 버킷으로 복사하고, EC2 인스턴스에서 이들 파일을 다운로드했습니다. 시청해 주셔서 감사합니다.</p>
</span></div></article></div><div class="docs-prevnext"><a class="docs-prev button" href="/aws-certification-study/docs/module2/script3"><span class="arrow-prev">← </span><span>Amazon Elastic Block Store(Amazon EBS)</span></a><a class="docs-next button" href="/aws-certification-study/docs/module2/script5"><span>AWS 글로벌 인프라</span><span class="arrow-next"> →</span></a></div></div></div><nav class="onPageNav"></nav></div><footer class="nav-footer" id="footer"><section class="sitemap"><a href="/aws-certification-study/" class="nav-home"><img src="/aws-certification-study/img/ausg logo.png" alt="AWS Certification Study" width="66" height="58"/></a><div><h5>Docs</h5><a href="/aws-certification-study/docs/en/doc1.html">Getting Started (or other categories)</a><a href="/aws-certification-study/docs/en/script1.html">Guides (or other categories)</a><a href="/aws-certification-study/docs/en/script2.html">API Reference (or other categories)</a></div><div><h5>Community</h5><a href="/aws-certification-study/en/users.html">User Showcase</a><a href="https://stackoverflow.com/questions/tagged/" target="_blank" rel="noreferrer noopener">Stack Overflow</a><a href="https://discordapp.com/">Project Chat</a><a href="https://twitter.com/" target="_blank" rel="noreferrer noopener">Twitter</a></div><div><h5>More</h5><a href="https://github.com/ausg/aws-certification-study">GitHub</a><a class="github-button" href="https://github.com/ausg/aws-certification-study" data-icon="octicon-star" data-count-href="/facebook/docusaurus/stargazers" data-show-count="true" data-count-aria-label="# stargazers on GitHub" aria-label="Star this project on GitHub">Star</a><div class="social"><div class="fb-like" data-href="https://AUSG.github.io" data-colorscheme="dark" data-layout="standard" data-share="true" data-width="225" data-show-faces="false"></div></div></div></section><a href="https://opensource.facebook.com/" target="_blank" rel="noreferrer noopener" class="fbOpenSource"><img src="/aws-certification-study/img/oss_logo.png" alt="Facebook Open Source" width="170" height="45"/></a><section class="copyright">Copyright © 2019 @ausg</section></footer></div><script>window.fbAsyncInit = function() {FB.init({appId:'ausgkr',xfbml:true,version:'v2.7'});};(function(d, s, id){var js, fjs = d.getElementsByTagName(s)[0];if (d.getElementById(id)) {return;}js = d.createElement(s); js.id = id;js.src = '//connect.facebook.net/en_US/sdk.js';fjs.parentNode.insertBefore(js, fjs);}(document, 'script','facebook-jssdk'));
                </script></body></html>